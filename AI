# improved_dqn_traffic.py
# Simple, commented, and more robust DQN loop for your pygame intersection.

import pygame
import random
import time
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque
import numpy as np
import os

pygame.init()

# -------------------------
# Screen & graphics config
# -------------------------
SCREEN_WIDTH = 800
SCREEN_HEIGHT = 800
screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))
pygame.display.set_caption("Traffic Light Simulation with DQN Control")

WHITE = (255, 255, 255)
BLACK = (0, 0, 0)
GRAY = (128, 128, 128)
RED = (255, 0, 0)
YELLOW = (255, 255, 0)
GREEN = (0, 255, 0)
DARK_GRAY = (50, 50, 50)

# -------------------------
# Hyperparameters / config
# -------------------------
STATE_SIZE = 4                 # [num_vertical, num_horizontal, phase, time_in_phase]
ACTION_SIZE = 2                # 0: keep, 1: switch
GAMMA = 0.99
EPS_START = 1.0
EPS_MIN = 0.01
EPS_DECAY = 0.995              # multiplicative decay per decision step
LR = 1e-3
BATCH_SIZE = 64
MEMORY_SIZE = 20000
TARGET_UPDATE_FREQ = 200       # update target every N training steps
MIN_PHASE_TIME = 5.0           # seconds before allowing a light switch
YELLOW_DURATION = 3.0
DECISION_INTERVAL = 1.0        # agent decides every 1 second
SWITCH_PENALTY = 5.0           # additional negative reward for switching (discourages flicker)
SAVE_MODEL_EVERY = 5000        # save Q-network every N training steps
GRAD_CLIP = 5.0                # gradient clipping for stability

# Where to save model
MODEL_DIR = "saved_models"
os.makedirs(MODEL_DIR, exist_ok=True)

# -------------------------
# Device
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# DQN network
# -------------------------
class DQN(nn.Module):
    def __init__(self, state_size, action_size):
        super().__init__()
        self.fc1 = nn.Linear(state_size, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, action_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

# -------------------------
# Traffic & car classes
# -------------------------
class TrafficLight:
    """Simple visual traffic light with orientation; internal state: 'red','yellow','green'."""
    def __init__(self, x, y, orientation):
        self.x = x
        self.y = y
        self.orientation = orientation  # 'vertical' or 'horizontal'
        self.state = 'red'

    def draw(self, surface):
        if self.orientation == 'vertical':
            pygame.draw.rect(surface, DARK_GRAY, (self.x, self.y, 30, 90))
            pygame.draw.circle(surface, RED if self.state == 'red' else GRAY,    (self.x + 15, self.y + 15), 10)
            pygame.draw.circle(surface, YELLOW if self.state == 'yellow' else GRAY,(self.x + 15, self.y + 45), 10)
            pygame.draw.circle(surface, GREEN if self.state == 'green' else GRAY, (self.x + 15, self.y + 75), 10)
        else:
            pygame.draw.rect(surface, DARK_GRAY, (self.x, self.y, 90, 30))
            pygame.draw.circle(surface, RED if self.state == 'red' else GRAY,    (self.x + 15, self.y + 15), 10)
            pygame.draw.circle(surface, YELLOW if self.state == 'yellow' else GRAY,(self.x + 45, self.y + 15), 10)
            pygame.draw.circle(surface, GREEN if self.state == 'green' else GRAY, (self.x + 75, self.y + 15), 10)

class Car(pygame.sprite.Sprite):
    """Car with simple turning behavior and collision avoidance."""
    def __init__(self, x, y, direction, maneuver):
        super().__init__()
        self.original_direction = direction  # where it spawned from (used to pick the relevant traffic light)
        self.direction = direction            # current direction
        self.speed = random.uniform(100, 200) # pixels/sec
        self.color = (random.randint(0,255), random.randint(0,255), random.randint(0,255))
        self.maneuver = maneuver              # 'straight','left','right'
        self.is_turning = False

        # Images for orientation
        self.image_vertical = pygame.Surface([20, 40])
        self.image_vertical.fill(self.color)
        self.image_horizontal = pygame.Surface([40, 20])
        self.image_horizontal.fill(self.color)

        self.image = self.image_vertical if direction in ['up','down'] else self.image_horizontal
        self.rect = self.image.get_rect(topleft=(x,y))

    def update(self, dt, vertical_light, horizontal_light, all_sprites):
        """Return True if car left the screen (so main loop can count it)."""
        can_move = True

        # --- Simple forward sensor to avoid collisions ---
        sensor_rect = self.rect.copy()
        sensor_distance = 30
        if self.direction == 'up':
            sensor_rect.y -= sensor_distance
        elif self.direction == 'down':
            sensor_rect.y += sensor_distance
        elif self.direction == 'right':
            sensor_rect.x += sensor_distance
        elif self.direction == 'left':
            sensor_rect.x -= sensor_distance

        for car in all_sprites:
            if car is not self and sensor_rect.colliderect(car.rect):
                can_move = False
                break

        # --- Traffic light stopping logic ---
        # pick the light that controls this car based on spawn direction
        light = vertical_light if self.original_direction == 'up' else horizontal_light

        # approximate stop line location (tune these if you change road drawing)
        if self.original_direction == 'up':
            stop_line = 450
            front_edge = self.rect.top
        else:
            stop_line = 350
            front_edge = self.rect.right

        # stop when approaching stop line and light is not green
        if can_move and not self.is_turning:
            if light.state != 'green' and (stop_line - self.speed * dt) <= front_edge <= (stop_line + 10):
                can_move = False

        # --- Simple turning trigger (keeps turning conditions small & deterministic) ---
        if can_move and self.maneuver != 'straight' and not self.is_turning:
            turn_initiated = False
            new_direction = self.direction

            # left-turn: spawn from west and reach center x threshold
            if self.maneuver == 'left':
                if self.original_direction == 'right' and self.rect.centerx >= 360:
                    new_direction = 'up'
                    turn_initiated = True
            # right-turn: spawn from south and reach center y threshold
            elif self.maneuver == 'right':
                if self.original_direction == 'up' and self.rect.centery <= 420:
                    new_direction = 'right'
                    turn_initiated = True

            if turn_initiated:
                self.is_turning = True
                self.direction = new_direction
                old_center = self.rect.center
                self.image = self.image_vertical if new_direction in ['up','down'] else self.image_horizontal
                # re-center smoothly at a consistent place
                if new_direction == 'up':
                    self.rect = self.image.get_rect(center=(370, old_center[1]))
                elif new_direction == 'right':
                    self.rect = self.image.get_rect(center=(old_center[0], 420))
                else:
                    self.rect = self.image.get_rect(center=old_center)

        # --- Movement ---
        if can_move:
            move_amount = self.speed * dt
            if self.direction == 'up':
                self.rect.y -= move_amount
            elif self.direction == 'down':
                self.rect.y += move_amount
            elif self.direction == 'left':
                self.rect.x -= move_amount
            elif self.direction == 'right':
                self.rect.x += move_amount

        # --- If the car goes off-screen, signal removal ---
        went_off = False
        if (self.rect.bottom < 0 or self.rect.top > SCREEN_HEIGHT or
            self.rect.right < 0 or self.rect.left > SCREEN_WIDTH):
            self.kill()
            went_off = True

        return went_off

# -------------------------
# Rendering helpers
# -------------------------
def draw_roads(surface):
    """Draw the cross-shaped intersection and the dashed lanes."""
    pygame.draw.rect(surface, GRAY, (350, 0, 100, SCREEN_HEIGHT))
    pygame.draw.rect(surface, GRAY, (0, 350, SCREEN_WIDTH, 100))

    # vertical dashed lines
    for y in range(0, 350, 40):
        pygame.draw.rect(surface, WHITE, (398, y, 4, 20))
    for y in range(450, SCREEN_HEIGHT, 40):
        pygame.draw.rect(surface, WHITE, (398, y, 4, 20))
    # horizontal dashed lines
    for x in range(0, 350, 40):
        pygame.draw.rect(surface, WHITE, (x, 398, 20, 4))
    for x in range(450, SCREEN_WIDTH, 40):
        pygame.draw.rect(surface, WHITE, (x, 398, 20, 4))

# -------------------------
# Training helper
# -------------------------
def train_dqn(q_net, target_net, optimizer, memory, batch_size, gamma):
    if len(memory) < batch_size:
        return None  # not enough samples yet

    batch = random.sample(memory, batch_size)
    states, actions, rewards, next_states, dones = zip(*batch)

    states = torch.FloatTensor(states).to(device)
    next_states = torch.FloatTensor(next_states).to(device)
    actions = torch.LongTensor(actions).to(device)
    rewards = torch.FloatTensor(rewards).to(device)
    dones = torch.FloatTensor(dones).to(device)

    # gather Q(s,a) for the taken actions
    q_values = q_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)
    with torch.no_grad():
        next_q_values = target_net(next_states).max(1)[0]
        expected_q = rewards + gamma * next_q_values * (1.0 - dones)

    loss = nn.MSELoss()(q_values, expected_q)
    optimizer.zero_grad()
    loss.backward()
    # gradient clipping
    torch.nn.utils.clip_grad_norm_(q_net.parameters(), GRAD_CLIP)
    optimizer.step()
    return loss.item()

# -------------------------
# Main loop
# -------------------------
def main():
    clock = pygame.time.Clock()
    running = True

    vertical_light = TrafficLight(460, 250, 'vertical')
    horizontal_light = TrafficLight(250, 460, 'horizontal')

    all_sprites = pygame.sprite.Group()
    car_spawn_timer = 0.0
    spawn_interval = random.uniform(0.5, 3.0)

    # RL state
    current_phase = 0   # 0: vertical green, 1: horizontal green
    time_in_phase = 0.0
    is_yellow = False
    yellow_timer = 0.0
    prev_phase = 0

    decision_timer = 0.0
    last_state = None
    last_action = None
    total_steps = 0      # steps used for counting training steps
    train_steps = 0      # training updates counter

    q_net = DQN(STATE_SIZE, ACTION_SIZE).to(device)
    target_net = DQN(STATE_SIZE, ACTION_SIZE).to(device)
    target_net.load_state_dict(q_net.state_dict())
    optimizer = optim.Adam(q_net.parameters(), lr=LR)
    memory = deque(maxlen=MEMORY_SIZE)

    last_time = time.time()
    epsilon = EPS_START

    # optional bookkeeping
    cars_exited = 0

    while running:
        # --- events ---
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False

        # --- timing ---
        current_time = time.time()
        dt = current_time - last_time
        last_time = current_time

        # --- update phase timers ---
        time_in_phase += dt
        if is_yellow:
            yellow_timer += dt
            if yellow_timer >= YELLOW_DURATION:
                # switch phase after yellow
                is_yellow = False
                current_phase = 1 - prev_phase
                time_in_phase = 0.0

        # --- set light visuals ---
        if is_yellow:
            vertical_light.state = 'yellow' if prev_phase == 0 else 'red'
            horizontal_light.state = 'yellow' if prev_phase == 1 else 'red'
        else:
            vertical_light.state = 'green' if current_phase == 0 else 'red'
            horizontal_light.state = 'green' if current_phase == 1 else 'red'

        # --- update sprites (cars) ---
        # when update returns True it means a car left the screen (we count it)
        for car in list(all_sprites):  # list(...) so we can safely modify inside loop
            left = car.update(dt, vertical_light, horizontal_light, all_sprites)
            if left:
                cars_exited += 1

        # --- spawn cars randomly (traffic waves) ---
        car_spawn_timer += dt
        if car_spawn_timer > spawn_interval:
            car_spawn_timer = 0.0
            spawn_interval = random.uniform(0.5, 3.0)

            num_cars = 1
            if random.random() < 0.2:  # 20% chance for a small traffic wave
                num_cars = random.randint(2, 4)

            for _ in range(num_cars):
                spawn_point = random.choice(['south', 'west'])
                car = None
                if spawn_point == 'south':
                    maneuver = random.choice(['straight', 'straight', 'right'])
                    x = 410 if maneuver == 'right' else random.choice([370, 410])
                    car = Car(x, SCREEN_HEIGHT, 'up', maneuver)
                else:  # west
                    maneuver = random.choice(['straight', 'straight', 'left'])
                    y = 370 if maneuver == 'left' else random.choice([370, 410])
                    car = Car(-40, y, 'right', maneuver)

                if car:
                    all_sprites.add(car)

        # --- RL decision step ---
        decision_timer += dt
        if decision_timer >= DECISION_INTERVAL:
            decision_timer -= DECISION_INTERVAL

            # build state features
            # number of queued vehicles close to intersection (tunable thresholds)
            num_vertical = sum(1 for car in all_sprites if car.original_direction == 'up' and car.rect.centery > 450)
            num_horizontal = sum(1 for car in all_sprites if car.original_direction == 'right' and car.rect.centerx < 350)
            phase = current_phase
            time_p = time_in_phase

            # normalize / clip features to sensible ranges to help NN training
            # counts cap at 10 (anything beyond treated as congested)
            s_num_v = float(min(num_vertical, 10)) / 10.0
            s_num_h = float(min(num_horizontal, 10)) / 10.0
            s_phase = float(phase)
            # time_in_phase normalized to 30s cap
            s_time = float(min(time_p, 30.0)) / 30.0

            state = np.array([s_num_v, s_num_h, s_phase, s_time], dtype=np.float32)

            # Build reward from previous transition (if exists)
            if last_state is not None and last_action is not None:
                # reward: negative for queues (we want small queue), penalty for switching to discourage flicker
                # scale rewards to small magnitudes
                queue_penalty = - (num_vertical + num_horizontal) * 0.1
                action_penalty = -SWITCH_PENALTY * 0.1 if last_action == 1 else 0.0
                reward = queue_penalty + action_penalty

                # not using terminal/done here (we treat episodes as continuous)
                memory.append((last_state, last_action, reward, state, 0.0))

                # train a bit every step (if enough samples)
                loss = train_dqn(q_net, target_net, optimizer, memory, BATCH_SIZE, GAMMA)
                if loss is not None:
                    train_steps += 1

                    # target network update
                    if train_steps % TARGET_UPDATE_FREQ == 0:
                        target_net.load_state_dict(q_net.state_dict())

                    # periodic model save
                    if train_steps % SAVE_MODEL_EVERY == 0:
                        save_path = os.path.join(MODEL_DIR, f"qnet_step{train_steps}.pt")
                        torch.save(q_net.state_dict(), save_path)
                        print(f"[INFO] Saved model at step {train_steps} -> {save_path}")

            # choose action (epsilon-greedy)
            action = 0
            if not is_yellow:
                state_tensor = torch.FloatTensor([state]).to(device)
                if random.random() < epsilon:
                    action = random.randint(0, 1)
                else:
                    with torch.no_grad():
                        qvals = q_net(state_tensor)
                        action = int(qvals.argmax().item())

                # Prevent switch if min phase time not met
                if action == 1 and time_in_phase < MIN_PHASE_TIME:
                    action = 0

            # execute chosen action
            if action == 1:
                is_yellow = True
                yellow_timer = 0.0
                prev_phase = current_phase

            # store current as last for next step
            last_state = state
            last_action = int(action)

            # decay epsilon after decision
            epsilon = max(EPS_MIN, epsilon * EPS_DECAY)
            total_steps += 1

        # --- drawing ---
        screen.fill(BLACK)
        draw_roads(screen)
        vertical_light.draw(screen)
        horizontal_light.draw(screen)
        all_sprites.draw(screen)

        # display some debug text (simple)
        font = pygame.font.SysFont(None, 20)
        text = font.render(f"Cars: {len(all_sprites)}  Exited: {cars_exited}  Eps: {epsilon:.3f}", True, WHITE)
        screen.blit(text, (10, 10))

        pygame.display.flip()
        clock.tick(60)

    # Save final model on quit
    final_save = os.path.join(MODEL_DIR, "qnet_final.pt")
    torch.save(q_net.state_dict(), final_save)
    print("[INFO] Final model saved to", final_save)

    pygame.quit()


if __name__ == "__main__":
    main()